import streamlit as st
from presidio_analyzer import AnalyzerEngine
from presidio_analyzer.nlp_engine import NlpEngineProvider
from presidio_anonymizer import AnonymizerEngine
from presidio_anonymizer.entities import OperatorConfig
from PIL import Image

# --- Carregamento dos Motores e Configura√ß√£o ---
@st.cache_resource
def get_analyzer():
    """Cria e configura o motor de an√°lise do Presidio."""
    provider_config = {
        "nlp_engine_name": "spacy",
        "models": [{"lang_code": "pt", "model_name": "pt_core_news_lg"}]
    }
    provider = NlpEngineProvider(nlp_configuration=provider_config)
    nlp_engine = provider.create_engine()
    
    analyzer = AnalyzerEngine(
        nlp_engine=nlp_engine,
        supported_languages=["pt"]
    )
    return analyzer

@st.cache_resource
def get_anonymizer():
    """Cria o motor de anonimiza√ß√£o."""
    return AnonymizerEngine()

try:
    analyzer = get_analyzer()
    anonymizer = get_anonymizer()
    st.set_page_config(page_title="L'Or√©al GPT - Privacy Partner", layout="centered")

    # Carrega o arquivo CSS
    with open(".streamlit/style.css") as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

except Exception as e:
    st.error(f"Erro ao carregar modelos: {e}")
    st.stop()

# --- Interface do Mockup ---

# Sidebar com √≠cones (simula√ß√£o)
with st.sidebar:
    st.write(" Chats Recentes")
    st.button("üí¨ An√°lise de Campanha", use_container_width=True)
    st.button("üìä Relat√≥rio de Vendas", use_container_width=True)
    st.button("üìù Ideias para Posts", use_container_width=True)
    st.button("üìÑ Tradu√ß√£o de Documento", use_container_width=True)

# Bloco para exibir a Logo
try:
    logo = Image.open("logo_loreal_gpt.png")
    # CORRE√á√ÉO APLICADA AQUI:
    st.image(logo, use_column_width=True) # Alterado para o novo par√¢metro
except FileNotFoundError:
    st.title("L'OR√âAL GPT") # Fallback caso a imagem n√£o seja encontrada

st.markdown("<h3 style='text-align: center; color: #555; font-weight: normal;'>Bem-vindo √† plataforma de IA Generativa da L'Or√©al.</h3>", unsafe_allow_html=True)
st.write("") # Adiciona um espa√ßo

# Inicializa o estado da sess√£o para guardar as mensagens
if 'messages' not in st.session_state:
    st.session_state.messages = []

# Exibe as mensagens do hist√≥rico
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input do usu√°rio
prompt = st.chat_input("Digite seu prompt ou cole um texto para an√°lise...")

if prompt:
    # Adiciona a mensagem do usu√°rio ao hist√≥rico
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # --- L√ìGICA DO PRIVACY PARTNER ---
    with st.spinner("Analisando em busca de riscos de privacidade..."):
        analyzer_results = analyzer.analyze(text=prompt, language="pt")

    # Se encontrar riscos, mostra o alerta e n√£o continua
    if analyzer_results:
        alert_message = f"""
        üö® **ALERTA DO PRIVACY PARTNER!** üö®

        O texto que voc√™ inseriu cont√©m **{len(analyzer_results)}** tipo(s) de informa√ß√µes pessoais/sens√≠veis.
        
        **Riscos Detectados:**
        """
        tipos_de_risco = list(set([res.entity_type for res in analyzer_results]))
        for tipo in tipos_de_risco:
            alert_message += f"\n- {tipo}"

        alert_message += """
        \n\n**A√ß√£o:** Conforme os Termos de Uso, para proteger os dados de nossos clientes e colaboradores, este prompt n√£o ser√° processado. Por favor, remova os dados sens√≠veis e tente novamente.
        """
        
        st.session_state.messages.append({"role": "assistant", "content": alert_message})
        with st.chat_message("assistant"):
            st.warning(alert_message)

    # Se n√£o encontrar riscos, simula uma resposta normal do GPT
    else:
        response_message = "‚úÖ **Privacy Partner:** Nenhuma informa√ß√£o sens√≠vel detectada. Seu prompt foi processado com seguran√ßa. \n\n (Aqui viria a resposta normal do L'Or√©al GPT...)"
        st.session_state.messages.append({"role": "assistant", "content": response_message})
        with st.chat_message("assistant"):
            st.success(response_message)
